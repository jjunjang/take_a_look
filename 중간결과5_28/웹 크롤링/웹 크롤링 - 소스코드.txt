from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from bs4 import BeautifulSoup
import csv
import time

Result = []

# chromedriver 사용.
driver = webdriver.Chrome('D:\chromedriver.exe')
driver.get('https://www.imdb.com/title/tt4154796/reviews?ref_=tt_ov_rt')

# 바디 영역 저장
body = driver.find_element_by_tag_name("body")

# 이제 load - More 을 계속 눌러서 페이지를 봐야되는데, 이걸 콜백형식으로 구현하는거 알아보기 힘들것 같아서 그냥 임의의 값 50 줘 봄 (폴링형식임, 개선 예정)
num_of_pagedowns = 50

#반복하면서 load - More를 눌르는 과정이고, find_element_by_-xpath("//*id='아이디']")는 문법이라 생각하면 됨.
while num_of_pagedowns:
    time.sleep(0.1)
    num_of_pagedowns -= 1

    try:
        driver.find_element_by_xpath("//*[@id='load-more-trigger']").click()
    except:
        None

time.sleep(1)


# [BeautifulSoup] html
html = driver.page_source
soup = BeautifulSoup(html, "html.parser")

# 배열 Result에 추가
for link in soup.find_all('div','text show-more__control'):
    Result.append(link.text.strip())


# 예외 제외란
for i in range(len(Result)):
    A = str(Result[i])
    A=A.replace("\"","")
    A=A.replace('**SPOILER ALERT**','')
    A=A.replace('**Spoilers alert**','')
    Result[i] = A


#배열 파일 저장란 (\t)구분
with open("D:\Project\WebCrowling\\tt4154796.csv", 'w', encoding='utf-8') as f:
    writer = csv.writer(f)
    for row in Result:
        writer.writerow([row])
        writer.writerow('\t')